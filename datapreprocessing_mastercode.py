# -*- coding: utf-8 -*-
"""DataPreprocessing_MasterCode.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-XWQrE206XRD6gHHrqhgP85BQ0KHHQTR

# Table of Contents
1.[Non_linear_data_transformed_to_linear_data](#Non_linear_data_transformed_to_linear_data)
2.[Train test Split](#Train-test-Split)
3.[Using sklearn's train_test_split](#Using-sklearn's-train_test_split)
4.[Label Encoder](#Label-Encoder)
5.[Ordinal Encoder](#Ordinal-Encoder)
6.[Why never to use pd.get dummies](#Why-never-to-use-pd.get-dummies)
7.[One hot encoder](#One-hot-encoder)
8.[Simple Imputer](#Simple-Imputer)
9.[KNN Imputer](#KNN-Imputer)
10.[Missing Indicator Imputer](#Missing-Indicator-Imputer)
11.[Standard scaler](#Standard-scaler)
12.[Min Max Scaler](#Min-Max-Scaler)
13.[Robust Scaler](#Robust-Scaler)
14.[MaxAbsScaler](#MaxAbsScaler)
15.[Power Transformer](#Power-Transformer)
16.[Quantile Transformer](#Quantile-Transformer)
17.[Normalizer Transformer](#Normalizer-Transformer)
18.[Function Transformer(log and expo)](#Function-Transformer(log-and-expo))
19.[Column Transformer-1](#Column-Transformer-1)
20.[Column Transformer-2](#Column-Transformer-2)
21.[Pipeline](#Pipeline)
22.[Cross Validation](#Cross-Validation)
23.[confusion matrix metrics + ROC & PR curves](#confusion-matrix-metrics-+-ROC-&-PR-curves)
24.[Plotting ROC & Precision-Recall Curves using sklearn functions](#Plotting-ROC-&-Precision-Recall-Curves-using-sklearn-functions)
25.[R2-Score](#R2-Score)
26.[ROC (Receiver Operating Characteristic ) Curve](#ROC-(Receiver-Operating-Characteristic-)-Curve)
27.[AUC (Area Under the Curve ) Score](#ROC-(Receiver-Operating-Characteristic-)-CurveAUC-(Area-Under-the-Curve-)-Score)
28.[Z score for hamdling outliers](#Z-score-for-hamdling-outliers)
29.[IQR for handling outliers](#IQR-for-handling-outliers)
30.[Winsorizing Outliers](#Winsorizing-Outliers)
31.[SMOTE-Handling Imbalanced dataset](#SMOTE-Handling-Imbalanced-dataset)
32.[Upsampling for imbalanced data](#Upsampling-for-imbalanced-data)
33.[Fancy Imputer(MICE) and 8 other imputer algorithms](#Fancy-Imputer(MICE)-and-8-other-imputer-algorithms)
34.[MICE imputation](#MICE-imputation)
35.[Iterative imputer](#Iterative-imputer.)

# Non_linear_data_transformed_to_linear_data
"""

x = [3,4,5,6,7,8]
y = [15,20,27,39,59,85]
# non linear data
import matplotlib.pyplot as plt
plt.plot(x,y,marker = 'o')
plt.show()

import numpy as np
log_y = np.log(1) + 2*np.log(x)
log_x = np.log(x)
plt.plot(log_x,log_y,marker = 'o')
plt.show()

"""# see how the graph is transfomed from a non linear to a linear scale

# Train test Split
"""

import pandas as pd
import numpy as np

df = pd.read_csv('data/income_evaluation.csv')
df.head()

df.shape

df = df.sample(frac=1)

df.head()

len(df) * 0.8

train = df[:26048]

test = df[26048:]

train.head()

train.columns

train.columns = train.columns.str.lstrip()

test.columns = test.columns.str.lstrip()

X_train = train.drop('income', axis=1)

X_train.head()

y_train = train.income

y_train.head()

X_test = test.drop('income', axis='columns')

y_test = test.income



"""# Using sklearn's train_test_split"""

d = pd.read_csv('data/income_evaluation.csv')
d.head()

from sklearn.model_selection import train_test_split

X = d.drop(' income', axis=1)
y = d[' income']

X1, X2, y1, y2 = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)

y1.value_counts()

y2.value_counts()

y.value_counts()

"""24720 is the total number of "<=50K" data samples. <br>These will be split in the ratio of 80:20

In the 'training y', i.e. y1, we'll have 24720 * 0.8 = 19776 "<=50K" samples
"""

24720*0.8

"""In the 'testing y', i.e. y2, we'll have 24720 * 0.2 = 4944 "<=50K" samples"""

24720*0.2

"""7841 is the total number of ">50K" data samples. <br>These will be split in the ratio of 80:20

In the 'testing y', i.e. y2, we'll have 7841 * 0.2 = 1568 ">50K" samples (rounding off)
"""

7841*0.2

"""In the 'training y', i.e. y1, we'll have 7841 * 0.8 = 6273 ">50K" samples (rounding off)"""

7841*0.8

X1.head()

"""# Label Encoder"""

import pandas as pd
import numpy as np

df = pd.read_csv('data/income_evaluation.csv')
df.head()

df.columns

df[' income'].value_counts()

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(df.drop(' income', axis=1), df[' income'],
                                                   test_size=0.2, random_state=0)

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

le.fit(y_train)

le.classes_

y_train

pd.Series(le.transform(y_train))

le.transform(y_test)

X_train[' native-country']

le1 = LabelEncoder()
le1.fit_transform(X_train[' native-country'])

pd.Series(le1.fit_transform(X_train[' native-country']))

"""# Ordinal Encoder"""

import pandas as pd
from sklearn.model_selection import train_test_split

df = pd.read_csv('data/income_evaluation.csv')
df.head()

X_train, X_test, y_train, y_test = train_test_split(df.drop([' income'], axis=1), df[' income'],
                                                           test_size=0.2, random_state=0)

X_train[' education'].value_counts()

X_train[' education'].unique()

X_train[' sex'].unique()

gender = [' Male', ' Female']

edu = [' Preschool', ' 1st-4th', ' 5th-6th', ' 7th-8th', ' 9th', ' 10th',
       ' 11th', ' 12th', ' HS-grad', ' Prof-school', ' Some-college',
       ' Assoc-acdm', ' Assoc-voc',' Bachelors', ' Masters', ' Doctorate' ]

from sklearn.preprocessing import OrdinalEncoder

ordi = OrdinalEncoder(categories=[edu, gender])

ordi.fit(X_train[[' education', ' sex']])

X_train[[' education', ' sex']]

pd.DataFrame(ordi.transform(X_train[[' education', ' sex']]))

ordi.transform(X_test[[' education', ' sex']])

"""# Why never to use pd.get dummies"""

import pandas as pd

flowers = pd.DataFrame({
    'color' : ['red', 'green', 'red', 'green', 'red', 'green', 'red', 'green', 'blue', 'blue'],
    'height': [4,9,4,8,4,7,4,7.5,20,19],
    'petals': [3,9,1,8,1,10,2,8,50,47],
    'days'  : [6,16,7,15,8,17,5,12,40,45]
})
flowers

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(flowers.drop('days', axis=1), flowers['days'],
                                                    test_size=0.2, random_state=40
)

X_train

X_train.info()

X_train['color'].unique()

pd.get_dummies(X_train).join(X_train['color'])

X_test

pd.get_dummies(X_test)

"""# One hot encoder"""

import pandas as pd

flowers = pd.DataFrame({
    'color' : ['red', 'green', 'red', 'green', 'red', 'green', 'red', 'green', 'blue', 'blue'],
    'height': [4,9,4,8,4,7,4,7.5,20,19],
    'petals': [3,9,1,8,1,10,2,8,50,47],
    'days'  : [6,16,7,15,8,17,5,12,40,45]
})
flowers

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(flowers.drop('days', 1), flowers['days'],
                                                    test_size=.2, random_state=40)

from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder(sparse=False)

X_train[['color']]

ohe.fit(X_train[['color']])

ohe.transform(X_train[['color']])

X_test

ohe.transform(X_test[['color']])



flowers_new = pd.DataFrame({
    'color' : ['red', 'green', 'red', 'pink', 'red', 'green', 'red', 'green', 'blue', 'blue'],
    'height': [4,9,4,8,4,7,4,7.5,20,19],
    'petals': [3,9,1,8,1,10,2,8,50,47],
    'days'  : [6,16,7,15,8,17,5,12,40,45]
})
flowers_new

X_1, X_2, y_1, y_2 = train_test_split(flowers_new.drop('days', 1), flowers_new['days'],
                                                    test_size=.2, random_state=40)

enc1 = OneHotEncoder(sparse=False, handle_unknown='ignore')

X_1['color']

X_2

enc1.fit_transform(X_1[['color']])

enc1.transform(X_2[['color']])





df = pd.read_csv('data/income_evaluation.csv')
df.head()

X_train, X_test, y_train, y_test = train_test_split(df.drop(' income', 1), df[' income'],
                                                    test_size=.2, random_state=40)

X_train[' workclass'].unique()

o1 = OneHotEncoder()

o1.fit_transform(X_train[[' workclass']]).toarray()

pd.DataFrame(o1.fit_transform(X_train[[' workclass']]).toarray())

o1.transform(X_test[[' workclass']]).toarray()



o2 = OneHotEncoder(sparse=False)

o2.fit_transform(X_train[[' workclass', ' occupation']])

X_train[' workclass'].nunique()

pd.DataFrame(o2.fit_transform(X_train[[' workclass', ' occupation']]))

o2.get_feature_names()

pd.set_option('display.max_columns', None)

pd.DataFrame(o2.fit_transform(X_train[[' workclass', ' occupation']]), columns=o2.get_feature_names())

categ = [col for col in X_train.columns if X_train[col].dtypes == 'O']

o3 = OneHotEncoder(sparse=False)

o3.fit_transform(X_train[categ])

X_train[' workclass'].unique()

pd.DataFrame(o3.fit_transform(X_train[categ])).shape

len(categ)



"""## now using drop='first', we'll notice how 8 columns have been removed, and now we have 102 - 8 = 94 columns."""

o4 = OneHotEncoder(sparse=False, drop='first')

o4.fit_transform(X_train[categ])

pd.DataFrame(o4.fit_transform(X_train[categ])).shape

"""# Simple Imputer"""

import pandas as pd
import numpy as np
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split

df = pd.read_csv('data/income_evaluation.csv', na_values = ' ?')
df.head()

df.isna().sum()



# hours per week missing values
np.random.seed(seed=0)
h = np.random.choice(a=df.index, replace=False, size=20)
df.loc[h, ' hours-per-week'] = np.nan

# age missing values
np.random.seed(seed=10)
a = np.random.choice(a=df.index, replace=False, size=28)
df.loc[a, 'age'] = np.nan

X_train, X_test, y_train, y_test = train_test_split(df.drop(' income', axis=1),
                                                    df[' income'], test_size=0.2,
                                                    random_state=30)

si_age = SimpleImputer(strategy='mean', add_indicator=True)

a = pd.DataFrame(si_age.fit_transform(X_train[['age']]))

si_age.statistics_

a[a[1] == 1]

si_occ = SimpleImputer(strategy='constant', add_indicator=True, fill_value='not available')

si_occ.fit_transform(X_train[[' occupation']])

pd.DataFrame(si_occ.fit_transform(X_train[[' occupation']]))

si_age.transform(X_test[['age']])

b = pd.DataFrame(si_age.transform(X_test[['age']]))

b[b[1] == 1]

"""# KNN Imputer"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

df = pd.read_csv('data/income_evaluation.csv', na_values=' ?')
df.head()

df[' education'].unique()

df.isna().sum()

# hours per week
np.random.seed(seed=0)
h = np.random.choice(a=df.index, replace=False, size=20)
df.loc[h, ' hours-per-week'] = np.nan

# age
np.random.seed(seed=10)
a = np.random.choice(a=df.index, replace=False, size=28)
df.loc[a, 'age'] = np.nan

df.isna().sum()

X_train, X_test, y_train, y_test = train_test_split(df.drop(' income', 1), df[' income'],
                                                   test_size=0.2, random_state=5)

from sklearn.impute import KNNImputer

knn = KNNImputer(n_neighbors=5, add_indicator=True)

X_train['age'].dtypes

X_train.columns

num = [col for col in X_train.columns if X_train[col].dtypes != 'O']

X_train[num].head()

knn.fit(X_train[num])

knn.transform(X_train[num])

pd.DataFrame(knn.transform(X_train[num])).head()

X_test[num].isna().sum()

knn.transform(X_test[num])

pd.DataFrame(knn.transform(X_test[num])).isna().sum().sum()

"""# Missing Indicator Imputer"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

df = pd.read_csv('data/income_evaluation.csv', na_values=' ?')
df.head()

df.isna().sum()

X_train, X_test, y_train, y_test = train_test_split(df.drop(' income', 1), df[' income'],
                                                   test_size=0.2, random_state=5)

from sklearn.impute import MissingIndicator

mi = MissingIndicator()

mi.fit(X_train)

pd.DataFrame(mi.transform(X_train)).head()

X_train.isna().sum()

mi1 = MissingIndicator(features='all')

pd.DataFrame(mi1.fit_transform(X_train)).head()

mi.features_

X_train.columns[mi.features_]

"""# Standard scaler"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import numpy as np
import seaborn as sns
from sklearn.preprocessing import StandardScaler

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.pipeline import Pipeline

from sklearn.datasets import fetch_california_housing

X, y = fetch_california_housing(as_frame=True, return_X_y=True)

X.shape

X.head()

X = X.iloc[:, :-2]

y.head()

X.describe()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

def plots(df, var, t):
    plt.figure(figsize=(13,5))
    plt.subplot(121)
    sns.kdeplot(df[var])
    plt.title('before ' + str(t).split('(')[0])
    
    plt.subplot(122)
    p1 = t.fit_transform(df[[var]]).flatten()
    sns.kdeplot(p1)
    plt.title('after ' + str(t).split('(')[0])

for col in X_train.columns:
    plots(X_train, col, StandardScaler())



def model_accuracy_scaled(mod):
    model_scaled = Pipeline([
        ('scale', StandardScaler()),
        ('model', mod)
    ])
    model_scaled.fit(X_train, y_train)
    return model_scaled.score(X_test, y_test)

def model_accuracy_unscaled(mod):
    model_unscaled = Pipeline([
        ('model', mod)
    ])
    model_unscaled.fit(X_train, y_train)
    return model_unscaled.score(X_test, y_test)

model_accuracy_scaled(KNeighborsRegressor())

model_accuracy_unscaled(KNeighborsRegressor())



model_accuracy_scaled(RandomForestRegressor(random_state=0))

model_accuracy_unscaled(RandomForestRegressor(random_state=0))

"""# Min Max Scaler"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import numpy as np
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.pipeline import Pipeline

from sklearn.datasets import fetch_california_housing

X, y = fetch_california_housing(return_X_y=True, as_frame=True)

X.head()

y.head()

X = X.iloc[:, :-2]

X.head()

def plots(df, var, t):
    plt.figure(figsize=(13,5))
    plt.subplot(121)
    sns.kdeplot(df[var])
    plt.title('before ' + str(t).split('(')[0])
    
    plt.subplot(122)
    p1 = t.fit_transform(df[[var]]).flatten()
    sns.kdeplot(p1)
    plt.title('after ' + str(t).split('(')[0])

for col in X.columns:
    plots(X, col, MinMaxScaler())

X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size=0.2, random_state=0)

def model_accuracy_scaled(mod):
    model_scaled = Pipeline([
        ('scale', MinMaxScaler()),
        ('model', mod)
    ])
    model_scaled.fit(X_train, y_train)
    return model_scaled.score(X_test, y_test)

def model_accuracy_unscaled(mod):
    model_unscaled = Pipeline([
        ('model', mod)
    ])
    model_unscaled.fit(X_train, y_train)
    return model_unscaled.score(X_test, y_test)

model_accuracy_scaled(KNeighborsRegressor())

model_accuracy_unscaled(KNeighborsRegressor())

model_accuracy_scaled(RandomForestRegressor(random_state=0))

model_accuracy_unscaled(RandomForestRegressor(random_state=0))

"""# Robust Scaler"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import numpy as np
import seaborn as sns
from sklearn.preprocessing import RobustScaler

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.pipeline import Pipeline

from sklearn.datasets import fetch_california_housing

X, y = fetch_california_housing(return_X_y=True, as_frame=True)

X.head()

y.head()

X = X.iloc[:, :-2]

X.head()

def plots(df, var, t):
    plt.figure(figsize=(13,5))
    plt.subplot(121)
    sns.kdeplot(df[var])
    plt.title('before ' + str(t).split('(')[0])
    
    plt.subplot(122)
    p1 = t.fit_transform(df[[var]]).flatten()
    sns.kdeplot(p1)
    plt.title('after ' + str(t).split('(')[0])

for col in X.columns:
    plots(X, col, RobustScaler())

X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size=0.2, random_state=0)

def model_accuracy_scaled(mod):
    model_scaled = Pipeline([
        ('scale', RobustScaler()),
        ('model', mod)
    ])
    model_scaled.fit(X_train, y_train)
    return model_scaled.score(X_test, y_test)

def model_accuracy_unscaled(mod):
    model_unscaled = Pipeline([
        ('model', mod)
    ])
    model_unscaled.fit(X_train, y_train)
    return model_unscaled.score(X_test, y_test)

model_accuracy_scaled(KNeighborsRegressor())

model_accuracy_unscaled(KNeighborsRegressor())

model_accuracy_scaled(RandomForestRegressor(random_state=0))

model_accuracy_unscaled(RandomForestRegressor(random_state=0))

"""# MaxAbsScaler"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import numpy as np
import seaborn as sns
from sklearn.preprocessing import MaxAbsScaler

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.pipeline import Pipeline

from sklearn.datasets import fetch_california_housing

X, y = fetch_california_housing(return_X_y=True, as_frame=True)

X.head()

y.head()

X = X.iloc[:, :-2]

X.head()

def plots(df, var, t):
    plt.figure(figsize=(13,5))
    plt.subplot(121)
    sns.kdeplot(df[var])
    plt.title('before ' + str(t).split('(')[0])
    
    plt.subplot(122)
    p1 = t.fit_transform(df[[var]]).flatten()
    sns.kdeplot(p1)
    plt.title('after ' + str(t).split('(')[0])

for col in X.columns:
    plots(X, col, MaxAbsScaler())

X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size=0.2, random_state=0)

def model_accuracy_scaled(mod):
    model_scaled = Pipeline([
        ('scale', MaxAbsScaler()),
        ('model', mod)
    ])
    model_scaled.fit(X_train, y_train)
    return model_scaled.score(X_test, y_test)

def model_accuracy_unscaled(mod):
    model_unscaled = Pipeline([
        ('model', mod)
    ])
    model_unscaled.fit(X_train, y_train)
    return model_unscaled.score(X_test, y_test)

model_accuracy_scaled(KNeighborsRegressor())

model_accuracy_unscaled(KNeighborsRegressor())

model_accuracy_scaled(RandomForestRegressor(random_state=0))

model_accuracy_unscaled(RandomForestRegressor(random_state=0))

"""# Power Transformer"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import numpy as np
import seaborn as sns
from sklearn.preprocessing import PowerTransformer

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.pipeline import Pipeline

from sklearn.datasets import fetch_california_housing

X, y = fetch_california_housing(return_X_y=True, as_frame=True)

X.head()

y.head()

X = X.iloc[:, :-2]

X.head()

X.describe()

def plots(df, var, t):
    plt.figure(figsize=(13,5))
    plt.subplot(121)
    sns.kdeplot(df[var])
    plt.title('before ' + str(t).split('(')[0])
    
    plt.subplot(122)
    p1 = t.fit_transform(df[[var]]).flatten()
    sns.kdeplot(p1)
    plt.title('after ' + str(t).split('(')[0])

for col in X.columns:
    plots(X, col, PowerTransformer(method='box-cox'))



X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size=0.2, random_state=0)

p = PowerTransformer(method='box-cox')
p.fit_transform(X_train)

p.lambdas_

def model_accuracy_scaled(mod):
    model_scaled = Pipeline([
        ('scale', PowerTransformer(method='box-cox')),
        ('model', mod)
    ])
    model_scaled.fit(X_train, y_train)
    return model_scaled.score(X_test, y_test)

def model_accuracy_unscaled(mod):
    model_unscaled = Pipeline([
        ('model', mod)
    ])
    model_unscaled.fit(X_train, y_train)
    return model_unscaled.score(X_test, y_test)

model_accuracy_scaled(KNeighborsRegressor())

model_accuracy_unscaled(KNeighborsRegressor())

model_accuracy_scaled(RandomForestRegressor(random_state=0))

model_accuracy_unscaled(RandomForestRegressor(random_state=0))

"""# Quantile Transformer"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import numpy as np
import seaborn as sns
from sklearn.preprocessing import QuantileTransformer

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.pipeline import Pipeline

from sklearn.datasets import fetch_california_housing

X, y = fetch_california_housing(return_X_y=True, as_frame=True)

X.head()

y.head()

X = X.iloc[:, :-2]

X.head()

X.describe()

def plots(df, var, t):
    plt.figure(figsize=(13,5))
    plt.subplot(121)
    sns.kdeplot(df[var])
    plt.title('before ' + str(t).split('(')[0])
    
    plt.subplot(122)
    p1 = t.fit_transform(df[[var]]).flatten()
    sns.kdeplot(p1)
    plt.title('after ' + str(t).split('(')[0])

for col in X.columns:
    plots(X, col, QuantileTransformer(output_distribution='normal'))



X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size=0.2, random_state=0)

p = QuantileTransformer(output_distribution='normal')
p.fit_transform(X_train)

p.quantiles_

def model_accuracy_scaled(mod):
    model_scaled = Pipeline([
        ('scale', QuantileTransformer(output_distribution='normal')),
        ('model', mod)
    ])
    model_scaled.fit(X_train, y_train)
    return model_scaled.score(X_test, y_test)

def model_accuracy_unscaled(mod):
    model_unscaled = Pipeline([
        ('model', mod)
    ])
    model_unscaled.fit(X_train, y_train)
    return model_unscaled.score(X_test, y_test)

model_accuracy_scaled(KNeighborsRegressor())

model_accuracy_unscaled(KNeighborsRegressor())

model_accuracy_scaled(RandomForestRegressor(random_state=0))

model_accuracy_unscaled(RandomForestRegressor(random_state=0))

"""# Normalizer Transformer"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import numpy as np
import seaborn as sns
from sklearn.preprocessing import Normalizer, StandardScaler

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.pipeline import Pipeline

from sklearn.datasets import fetch_california_housing

X, y = fetch_california_housing(return_X_y=True, as_frame=True)

X.head()

X = X.iloc[:, :-2]

X.head()

def plots(df, var, t):
    plt.figure(figsize=(13,5))
    plt.subplot(121)
    sns.distplot(df[var])
    plt.title('before ' + str(t).split('(')[0])
    
    plt.subplot(122)
    p1 = t.fit_transform(df[[var]]).flatten()
    sns.distplot(p1)
    plt.title('after ' + str(t).split('(')[0])

X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size=0.2, random_state=0)

for col in X_train.columns:
    plots(X_train, col, Normalizer())
    plt.show()

X_train['HouseAge'].head()

n = Normalizer(norm='max')
n.fit(X_train[['HouseAge']])

n.transform(X_train[['HouseAge']])

n.fit_transform(X_train)







def model_accuracy_scaled(mod):
    model_scaled = Pipeline([
        ('scale', Normalizer(norm='max')),
        ('model', mod)
    ])
    model_scaled.fit(X_train, y_train)
    return model_scaled.score(X_test, y_test)

def model_accuracy_unscaled(mod):
    model_unscaled = Pipeline([
        ('model', mod)
    ])
    model_unscaled.fit(X_train, y_train)
    return model_unscaled.score(X_test, y_test)

model_accuracy_scaled(KNeighborsRegressor())

model_accuracy_unscaled(KNeighborsRegressor())

model_accuracy_scaled(RandomForestRegressor(random_state=0))

model_accuracy_unscaled(RandomForestRegressor(random_state=0))

"""### Model accuracy is declining for a tree based model when we used Normalizer for feature scaling!

# Function Transformer(log and expo)
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import numpy as np
import seaborn as sns
from sklearn.preprocessing import FunctionTransformer

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.pipeline import Pipeline

from sklearn.datasets import fetch_california_housing

X, y = fetch_california_housing(return_X_y=True, as_frame=True)

X.head()

y.head()

X = X.iloc[:, :-2]

X.head()

def plots(df, var, t):
    plt.figure(figsize=(13,5))
    plt.subplot(121)
    sns.kdeplot(df[var])
    plt.title('before ' + str(t).split('(')[0])
    
    plt.subplot(122)
    p1 = t.fit_transform(df[var])
    sns.kdeplot(p1)
    plt.title('after ' + str(t).split('(')[0])

X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size=0.2, random_state=0)

for col in X_train.columns:
    plots(X_train, col, FunctionTransformer(lambda x: x**(1/2)))

for col in X_train.columns:
    plots(X_train, col, FunctionTransformer(lambda x: np.power(x, (1/3))))

for col in X_train.columns:
    plots(X_train, col, FunctionTransformer(np.log1p))

f = FunctionTransformer(lambda x: np.power(x, 1/2))

X_train['HouseAge'].head()

f.fit(X_train['HouseAge'])
f.transform(X_train[['HouseAge']]).head()

def model_accuracy_scaled(mod):
    model_scaled = Pipeline([
        ('scale', FunctionTransformer(np.log1p)),
        ('model', mod)
    ])
    model_scaled.fit(X_train, y_train)
    return model_scaled.score(X_test, y_test)

def model_accuracy_unscaled(mod):
    model_unscaled = Pipeline([
        ('model', mod)
    ])
    model_unscaled.fit(X_train, y_train)
    return model_unscaled.score(X_test, y_test)

model_accuracy_scaled(KNeighborsRegressor())

model_accuracy_unscaled(KNeighborsRegressor())

model_accuracy_scaled(RandomForestRegressor(random_state=0))

model_accuracy_unscaled(RandomForestRegressor(random_state=0))

"""# Column Transformer-1"""

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import RobustScaler, OneHotEncoder

df = pd.read_csv('data/income_evaluation.csv', na_values=' ?')
df.head()

df.shape

df.isna().sum()

df.dropna(inplace=True)

df.shape

df.columns = df.columns.str.strip()
df.columns

df.isna().sum()

X_train, X_test, y_train, y_test = train_test_split(df.drop('income', axis=1), df.income,
                                                   test_size=0.2, random_state=0)



"""### Step 1: Scale the numerical columns
### Step 2: One Hot Encode the categorical columns
"""

df.info()

num_cols = [col for col in X_train.columns if X_train[col].dtypes!='O']
num_cols

cat_cols = [col for col in X_train.columns if X_train[col].dtypes=='O']
cat_cols

X_train[num_cols].head()

r = RobustScaler()
r.fit(X_train[num_cols])

X_train_num_scaled = r.transform(X_train[num_cols])

X_test_num_scaled = r.transform(X_test[num_cols])



X_train[cat_cols].head()

o = OneHotEncoder(sparse=False, handle_unknown='ignore')
o.fit(X_train[cat_cols])

X_train_cat_encoded = o.transform(X_train[cat_cols])

X_test_cat_encoded = o.transform(X_test[cat_cols])



pd.DataFrame(np.concatenate((X_train_num_scaled, X_train_cat_encoded), axis=1))

pd.DataFrame(np.concatenate((X_test_num_scaled, X_test_cat_encoded), axis=1))





"""# Column Transformer enters!"""

df.head()

df[['education', 'education-num']].head()

cat_cols

ct = ColumnTransformer([
    ('step1', RobustScaler(), num_cols),
    ('step2', OneHotEncoder(sparse=False, handle_unknown='ignore'), ['workclass',
                                                                     'marital-status', 'occupation',
                                                                     'relationship', 'race', 'sex',
                                                                     'native-country']),
], remainder='drop')

ct.fit(X_train)

ct.transform(X_train)

ct.transform(X_test)

pd.DataFrame(ct.transform(X_train)).head()

ct.transformers_

ct.transformers_[0][1].scale_

ct.transformers_[1][1].get_feature_names()



num_cols

ct1 = ColumnTransformer([
    ('step1', RobustScaler(), ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',]),
    ('step2', OneHotEncoder(sparse=False, handle_unknown='ignore'), ['workclass',
                                                                     'marital-status', 'occupation',
                                                                     'relationship', 'race', 'sex',
                                                                     'native-country']),
    ('step3', 'passthrough', ['hours-per-week']),
    ('step4', 'drop', ['education'])
], remainder='drop')

pd.DataFrame(ct1.fit_transform(X_train)).head()

"""# Column Transformer-2"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, RobustScaler
from sklearn.tree import DecisionTreeClassifier

df = pd.read_csv('data/income_evaluation.csv', na_values=' ?')

df.head()

df.columns

df.columns = df.columns.str.strip()
df.columns

df.isna().sum()

"""### Just to spice things up a little, I'll infuse missing values in numerical columns as well"""

np.array(df.index)

np.random.seed(15)

r = np.random.choice(df.index, size=40, replace=False)
print(r)
df.loc[r, 'age'] = np.nan

np.random.seed(25)

s = np.random.choice(df.index, size=40, replace=False)
print(s)
df.loc[s, 'hours-per-week'] = np.nan

df.isna().sum()

X_train, X_test, y_train, y_test = train_test_split(df.drop('income', 1), df.income, test_size=0.2,
                                                   random_state=40)



num_cols = [col for col in X_train.columns if X_train[col].dtypes!='O']
num_cols

cat_cols = [col for col in X_train.columns if (X_train[col].dtypes=='O') & (col!='education')]
cat_cols

"""## The not-so-good and unscalable approach"""

ct1 = ColumnTransformer([
    ('si_num', SimpleImputer(strategy='median', add_indicator=True), num_cols),
], remainder='drop')

pd.DataFrame(ct1.fit_transform(X_train)).head()

ct2 = ColumnTransformer([
    ('si_num', SimpleImputer(strategy='median', add_indicator=True), num_cols),
    ('rob_num', RobustScaler(), num_cols)
], remainder='drop')

pd.DataFrame(ct2.fit_transform(X_train)).head()



ct3 = ColumnTransformer([
    ('si_num', SimpleImputer(strategy='median', add_indicator=True), num_cols),
    ('si_cat', SimpleImputer(strategy='constant', fill_value='missing', add_indicator=True), cat_cols)
], remainder='drop')

pd.DataFrame(ct3.fit_transform(X_train)).head()

list(range(6))

list(range(8, 18))

ct4 = ColumnTransformer([
    ('rob_num', RobustScaler(), list(range(6))),
    ('ohe_cat', OneHotEncoder(sparse=False, handle_unknown='ignore'), list(range(8, 18)))
])

xtf = ct3.fit_transform(X_train)

ct4.fit_transform(xtf)



"""## The good and scalable approach"""



pp_num = Pipeline([
    ('num_imp', SimpleImputer(strategy='median', add_indicator=False)),
    ('rob_num', RobustScaler())
])

pp_cat = Pipeline([
    ('cat_imp', SimpleImputer(strategy='constant', add_indicator=False, fill_value='missing')),
    ('ohe_cat', OneHotEncoder(sparse=False, handle_unknown='ignore'))
])

from sklearn.impute import MissingIndicator

ct = ColumnTransformer([
    ('mi', MissingIndicator(), X_train.columns),
    ('pp_num', pp_num, num_cols),
    ('pp_cat', pp_cat, cat_cols)
])

xt = ct.fit_transform(X_train)
xt

pd.DataFrame(xt).head()

pd.DataFrame(xt).isna().sum().sum()

X_test.head()

ct.transform(X_test)

pipe_final = Pipeline([
    ('ct_step', ct),
    ('model', DecisionTreeClassifier())
])

pipe_final.fit(X_train, y_train)

pipe_final.predict(X_test)

pipe_final.score(X_test, y_test)

pipe_final.named_steps

pipe_final.named_steps['ct_step']

pipe_final.named_steps['ct_step'].named_transformers_

pipe_final.named_steps['ct_step'].named_transformers_['pp_cat']

pipe_final.named_steps['ct_step'].named_transformers_['pp_cat'].named_steps

pipe_final.named_steps['ct_step'].named_transformers_['pp_cat'].named_steps['ohe_cat']

pipe_final.named_steps['ct_step'].named_transformers_['pp_cat'].named_steps['ohe_cat'].get_feature_names()

"""# Pipeline"""

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import RobustScaler, OneHotEncoder, StandardScaler, MinMaxScaler
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.tree import DecisionTreeClassifier

df = pd.read_csv('data/income_evaluation.csv', na_values=' ?')
df.head()

df.isna().sum()

df.shape

df.dropna(inplace=True)
df.shape

df.isna().sum()

df.columns

df.columns = df.columns.str.strip()
df.columns

X_train, X_test, y_train, y_test = train_test_split(df.drop('income', axis=1), df.income,
                                                   test_size=0.2, random_state=0)

num_cols = [col for col in X_train.columns if X_train[col].dtypes!='O']
num_cols

cat_cols = [col for col in X_train.columns if X_train[col].dtypes=='O']
cat_cols

df[['education', 'education-num']].head()

ct = ColumnTransformer([
    ('step1', RobustScaler(), ['age', 'fnlwgt', 'hours-per-week']),
    ('step2', StandardScaler(), ['capital-gain', 'capital-loss', 'education-num']),
    ('step3', OneHotEncoder(sparse=False, handle_unknown='ignore'), ['workclass', 
                                                                     'marital-status', 'occupation',
                                                                     'relationship', 'race', 
                                                                     'sex', 'native-country'])
], remainder='drop')



"""# pipeline use case 1 - with an 'estimator' as final step"""

p = Pipeline([
    ('coltf_step', ct),
    ('model', DecisionTreeClassifier()),
])

p.fit(X_train, y_train)

p.predict(X_test)

p.score(X_test, y_test)

p.named_steps

p.named_steps['coltf_step'].transformers_

p.named_steps['coltf_step'].transformers_[2][1].get_feature_names()



p.named_steps['coltf_step'].transformers_[0][1].center_



"""# pipeline use case 2 - without an estimator as final step"""

p1 = Pipeline([
    ('coltf_step', ct),
    ('minmax', MinMaxScaler())
#     ('model', DecisionTreeClassifier()),
])

p1.fit(X_train)

p1.transform(X_test)

"""# Cross Validation"""

import pandas as pd
import numpy as np
import time
from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, LeaveOneOut,\
RepeatedKFold, train_test_split
from sklearn.preprocessing import OneHotEncoder, RobustScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier

df = pd.read_csv('data/income_evaluation.csv', na_values=' ?')
df.head()

df.isna().sum()

df.fillna('missing', inplace=True)

df.isna().sum()

X = df.drop(' income', axis=1)
y = df[' income']

X.shape

y.value_counts()

"""# KFold"""

kf = KFold(n_splits=5)

32561/5

6512*4

i = 1
for train_set, test_set in kf.split(X=X):
    print("iteration ", i)
    print(train_set, " having :" , len(train_set))
    print(test_set, " having :" , len(test_set))
    print("-------------------------")
    i += 1

num_cols = X.select_dtypes(include=np.number).columns
num_cols

cat_cols = X.select_dtypes(exclude=np.number).columns
cat_cols

ct = ColumnTransformer([
    ('rob', RobustScaler(), num_cols),
    ('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'), cat_cols)
])

pipe = Pipeline([
    ('ct_step', ct),
    ('model', RandomForestClassifier(n_estimators=10, random_state=0))
])

X.loc[6513:].head()

scores = []
i = 1
for train_set, test_set in kf.split(X):
    pipe.fit(X.loc[train_set], y[train_set])
    sco = pipe.score(X.loc[test_set], y[test_set])
    scores.append(sco)
    print("iteration ", i)
    i += 1

np.array(scores)

np.array(scores).mean()

np.array(scores).std()

"""# Stratified KFold"""

y.value_counts()

7841/5

24720/5

4944*4

skf = StratifiedKFold(n_splits=5)

scores_skf = []
i = 1
for train_set, test_set in skf.split(X, y):
    pipe.fit(X.loc[train_set], y[train_set])
    sco = pipe.score(X.loc[test_set], y[test_set])
    scores_skf.append(sco)
    print("iteration ", i)
    i += 1

scores_skf



i = 1
for train_set, test_set in skf.split(X=X, y=y):
    print("iteration ", i)
    print(train_set, " having :" , len(train_set))
    print(test_set, " having :" , len(test_set))
    print()
    print("y train counts: \n", y[train_set].value_counts())
    print("y test counts: \n", y[test_set].value_counts())
    print("-------------------------")
    i += 1



result_kf = cross_val_score(estimator=pipe, X=X, y=y, scoring='accuracy', cv=5)

result_kf



start = time.time()
result_kf10 = cross_val_score(estimator=pipe, X=X, y=y, scoring='accuracy', cv=KFold(n_splits=10))
result_kf10
print("time taken: ", time.time()-start)

result_kf10

"""# LOO CV"""

start = time.time()
result_loocv = cross_val_score(estimator=pipe, X=X.head(100), y=y.head(100),
                               scoring='accuracy', cv=LeaveOneOut())
print("time taken: ", time.time()-start)

"""It should've been 32561 technically, but makes very minimal difference really.
I don't change here just to keep it in sync with the video tutorial which you can access here btw:
https://www.youtube.com/watch?v=ZnSJgIULMVY
"""

32531/100

325*8

325*8/60

result_loocv

result_loocv.mean()

"""# Repeated KFold"""

start = time.time()
result_rkf = cross_val_score(estimator=pipe, X=X, y=y, scoring='accuracy',
                              cv=RepeatedKFold(n_splits=5, n_repeats=5))
result_rkf
print("time taken: ", time.time()-start)

result_rkf





"""#### Until now, we've seen implementation of cross validation on entire datasets, which isn't wrong.
#### But we can also do it on a training set, and then cross verify our results on a separate test set to see if we're able to generalize our results properly.
"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

start = time.time()
result_tts = cross_val_score(estimator=pipe, X=X_train, y=y_train,
                              scoring='accuracy', cv=KFold(n_splits=5))
print("time taken: ", time.time()-start)

result_tts

pipe.fit(X_train, y_train)

pipe.score(X_test, y_test)

"""#### By comparing this score with the 5 CV scores on the training set, we see the results are quite similar, which is a good sign"""



"""#### To see list of available scoring parameters, we can either remember this piece of code:
import sklearn
sorted(sklearn.metrics.SCORERS.keys())
#### or we can use this little hack where we set the scoing parameter to a random string, and then scikit-learn tells us in the error where the list of available metrics exist! 
"""

cross_val_score(estimator=pipe, X=X_train, y=y_train,
                              scoring='kemfi', cv=KFold(n_splits=5))

"""# confusion matrix metrics + ROC & PR curves"""

import sklearn
sorted(sklearn.metrics.SCORERS.keys())

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import RobustScaler, OneHotEncoder
from sklearn.linear_model import LogisticRegression

df = pd.read_csv('data/churn modelling.csv', index_col=0)
df.head()

df.drop(['CustomerId', 'Surname'], axis=1, inplace=True)

df.shape

df.isna().sum()

X = df.drop('Exited', 1)
y = df.Exited

y.value_counts()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)

X.columns

num_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']
cat_cols = ['HasCrCard', 'IsActiveMember', 'Geography', 'Gender']

ct = ColumnTransformer([
    ('s1', RobustScaler(), num_cols),
    ('s2', OneHotEncoder(sparse=False, handle_unknown='ignore'), cat_cols)
])

p = Pipeline([
    ('ct', ct),
    ('mod', LogisticRegression(random_state=0))
])

p.fit(X_train, y_train)

# predictions are for the default threshold of 0.5
preds = p.predict(X_test)
preds[:15]

# real class labels of the first 15 people in the test set
np.array(y_test)[:15]

from sklearn.metrics import confusion_matrix, plot_confusion_matrix

confusion_matrix(y_true=y_test, y_pred=preds)

p.classes_

"""![image.png](attachment:image.png)"""





"""And if we want to switch the class label positions:

![image.png](attachment:image.png)
"""

confusion_matrix(y_test, preds, labels=(1,0))

confusion_matrix(y_test, preds, labels=(1,0)).ravel()

tp, fn, fp, tn = confusion_matrix(y_test, preds, labels=(1,0)).ravel()

precision = tp/(tp+fp)
precision



from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,\
fbeta_score, matthews_corrcoef

precision_score(y_test, preds)

recall_score(y_test, preds)

# harmonic mean of precision and recall
f1_score(y_test, preds)

# Precision more weight than recall (beta < 1)
fbeta_score(y_test, preds, beta=0.5)

# recall more weight than precision (beta > 1)
fbeta_score(y_test, preds, beta=2)

# when both classes need to be predicted with good accuracies, MCC is better than F-measures
matthews_corrcoef(y_test, preds)

from sklearn.metrics import SCORERS

sorted(SCORERS.keys())



"""## Plotting ROC & Precision-Recall Curves using sklearn functions"""

from sklearn.metrics import plot_roc_curve, plot_precision_recall_curve, roc_curve

plot_roc_curve(p, X_test, y_test)
plt.plot([0,1], [0,1], c='k')

y_test.value_counts()

407/(1593+407)

plot_precision_recall_curve(p, X_test, y_test)
plt.plot([0,1], [0.2035,0.2035], c='k')
plt.legend(loc='best')

probs = p.predict_proba(X_test)[:, 1]
probs

p.classes_

from sklearn.preprocessing import Binarizer

binarizer = Binarizer(threshold=0.9)

s = binarizer.fit_transform([probs])
s

np.unique(s.ravel(), return_counts=True)





binarizer = Binarizer(threshold=0.1)

s = binarizer.fit_transform([probs])
s

np.unique(s.ravel(), return_counts=True)

fpr, tpr, thr = roc_curve(y_test, probs)

plt.scatter(fpr, tpr)

sorted(probs)

pd.DataFrame({
    'fpr':fpr,
    'tpr':tpr,
    'thr':thr
}).head()



from sklearn.metrics import roc_auc_score, average_precision_score

roc_auc_score(y_test, probs)

average_precision_score(y_test, probs)

"""# Plotting ROC & Precision-Recall Curves from scratch"""

def plot_roc_curve_from_scratch(y_true, thresholds):
    xax, yax = [], []
    for thr in thresholds:
        preds = Binarizer(threshold=thr).fit_transform([probs]).ravel()
        tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()
        
        fpr1 = fp/(fp+tn)
        tpr1 = tp/(tp+fn)
        
        xax.append(fpr1)
        yax.append(tpr1)
    return xax, yax

xax, yax = plot_roc_curve_from_scratch(y_test, np.linspace(0,1,30))

plt.scatter(xax, yax)



def plot_pr_curve_curve_from_scratch(y_true, thresholds):
    xax_pr, yax_pr = [], []
    for thr in thresholds:
        preds = Binarizer(threshold=thr).fit_transform([probs]).ravel()
        tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()
        
        precision = tp/(fp+tp)
        recall = tp/(tp+fn)
        
        xax_pr.append(recall)
        yax_pr.append(precision)
    return xax_pr, yax_pr

xax_pr, yax_pr = plot_pr_curve_curve_from_scratch(y_test, [0.1,0.2,0.3,0.4,0.5,0.6])

plt.scatter(xax_pr, yax_pr)

"""# R2-Score"""

y = [1,2,3]
y_predict = [1,2,4]

from sklearn.metrics import r2_score
r2_score(y,y_predict)

Image('r2score.jpeg', width=700)

"""* R2>0.9 : good model that means your model is 90 percent better than  mean model. 
* R2 = 1: Perfect model and zero error and SSR is 0.
* R2 = 0.5: bad model and it says that your mean model is 50 percent better than mean model
* R2 = 0: Model is no better than Mean model as SSR and SST are exactly same.
* R2 = Negative: SSR can be much higher than SST.That means your model is bad than a normal mean model.
"""

y = [1,2,3]
y_predict = [1,2,5]
r2_score(y,y_predict)

Image('r2scores.jpeg', width=700)

"""* r2 is negative That means your model is bad than a normal mean model.
* r2 score doesnt have any lower boundaries, infact it can go to any negative value but the top limit is 1

#  ROC (Receiver Operating Characteristic )  Curve
# AUC (Area Under the Curve ) Score
"""

import pandas as pd
data = pd.read_csv('breast_cancer.csv')
print(data.shape)
data.head()

data.corr().outcome.sort_values()

X = data.iloc[:,:-1]
y = data.outcome
X.head()

y.head()

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=10)

from sklearn.linear_model import LogisticRegression
model = LogisticRegression(C=100)
model.fit(X_train,y_train)
y_predict= model.predict(X_test)

from sklearn.metrics import accuracy_score
print(accuracy_score(y_test,y_predict))
pd.crosstab(y_test,y_predict)

model.predict_proba(X_test)[:,1]

import numpy as np
y_predict_th3 = np.where(model.predict_proba(X_test)[:,1]>0.3,1,0) # Threshold is 0.3
y_predict_th4 = np.where(model.predict_proba(X_test)[:,1]>0.4,1,0) # Threshold is 0.3

pd.crosstab(y_test,y_predict_th4)

def predict_threshold (model,X_test,thresholds):
    import numpy as np
    return np.where(model.predict_proba(X_test)[:,1]>thresholds,1,0) # Threshold is 0.3

import numpy as np
from sklearn.metrics import confusion_matrix
for thr in np.arange(0,1.0,0.1):
    y_predict = predict_threshold(model,X_test,thr)
    print("Threshold :",thr)
    print(confusion_matrix(y_test,y_predict))

from sklearn.metrics import roc_curve, roc_auc_score

tpr,fpr,thresholds = roc_curve(y_test,model.predict_proba(X_test)[:,1])

thresholds

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve,roc_auc_score
# %matplotlib inline
fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1],drop_intermediate=False)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.title('ROC curve for breast cancer classifier')
plt.xlabel('False Positive Rate (1 - Specificity)')
plt.ylabel('True Positive Rate (Sensitivity)')
plt.plot(fpr, tpr,color='red',lw=5)
plt.show()

roc_auc_score(y_test, model.predict_proba(X_test)[:,1])

"""#### Keep it in mind, this method of using Z scores for capping/ trimming the outliers is valid ONLY if the particular feature is normally distributed

#### We should ideally split the dataset into training and testing and then apply the outlier engineering techniques, because we want to keep the test set untouched until the very end.
#### But here, we'll assume that the entire data we have is our train set, and that we have a separate test set waiting for us

# Z score for hamdling outliers
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import scipy.stats as stats
import seaborn as sns

column = np.array([1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9, 100])

stats.zscore(column)

print("mean: {}".format(column.mean()))
print("std dev: {}".format(column.std()))

( 1 - 5) / 2.581988897471611



from sklearn.datasets import load_diabetes

dia = load_diabetes()

dir(dia)

X, y = dia.data, dia.target

data = np.concatenate((X,y.reshape(-1,1)), axis=1)

dia.feature_names

df = pd.DataFrame(data, columns=dia.feature_names+['target'])
df.head()

for col in dia.feature_names:
    plt.figure(figsize=(15,4))
    plt.subplot(131)
    sns.distplot(df[col], label="skew: " + str(np.round(df[col].skew(),2)))
    plt.legend()
    plt.subplot(132)
    sns.boxplot(df[col])
    plt.subplot(133)
    stats.probplot(df[col], plot=plt)
    plt.tight_layout()
    plt.show()



"""## Z score capping"""

df_cap = df.copy()

def zscore_capping(df, cols, thr):
    
    for col in cols:
        
        mean = df[col].mean()
        std = df[col].std()
        
        upper_bound = mean + thr*std
        lower_bound = mean - thr*std
        
        df[col] = np.where(df[col]>upper_bound, upper_bound,
                 np.where(df[col]<lower_bound, lower_bound, df[col]))

np.round(df.describe(), 4)

zscore_capping(df_cap, dia.feature_names, 3)

np.round(df_cap.describe(), 4)

0 + 3*0.0476





"""## Z score trimming"""



"""#### Keep it in mind, this method of using Z scores for capping/ trimming the outliers is valid ONLY if the particular feature is normally distributed

#### We should ideally split the dataset into training and testing and then apply the outlier engineering techniques only on the training set, because we want to keep the test set untouched until the very end.
#### But here, we'll assume that the entire data we have is our train set, and that we have a separate test set waiting for us
"""

df.head()

df_trim = df.copy()

def zscore_trim(df, cols, thr):
    
    drop_outliers = np.array([])
    
    for col in cols:
        
        mean = df[col].mean()
        std = df[col].std()
        
        upper_bound = mean + thr*std
        lower_bound = mean - thr*std
        
        s = df[col]
        
        indexes = s[(s>upper_bound) | (s<lower_bound)].index
        
        drop_outliers = np.append(drop_outliers, indexes)
        
    return drop_outliers

s = df['s1']
s[(s>0.1429) | (s<-0.1429)].index

dia.feature_names

dropped = np.unique(zscore_trim(df_trim, dia.feature_names, 3))
dropped

df_trim.drop(labels=dropped, inplace=True)

df.shape

df_trim.shape

12/442

"""#### We should ideally split the dataset into training and testing and then apply the outlier engineering techniques onto the training set, because we want to keep the test set untouched until the very end.

#### We'll want see how such a model performs on unseen data which may or may not contain outliers

#### But here, we'll assume that the entire data we have is our train set, and that we have a separate test set waiting for us

# IQR for handling outliers
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import scipy.stats as stats
import seaborn as sns

from sklearn.datasets import fetch_california_housing
ca = fetch_california_housing()

dir(ca)

X = ca.data

y = ca.target

data = np.concatenate((X,y.reshape(-1,1)), axis=1)

df = pd.DataFrame(data, columns=ca.feature_names+['target'])
df.head()

df.drop(['Latitude', 'Longitude'], axis=1, inplace=True)

features = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup',]
features

sns.set_style('dark')
for col in features:
    plt.figure(figsize=(15,4))
    plt.subplot(131)
    sns.distplot(df[col], label="skew: " + str(np.round(df[col].skew(),2)))
    plt.legend()
    plt.subplot(132)
    sns.boxplot(df[col])
    plt.subplot(133)
    stats.probplot(df[col], plot=plt)
    plt.tight_layout()
    plt.show()

"""#### The method of using Z scores for capping/ trimming the outliers is valid ONLY if the particular feature is normally distributed

#### Since our data here is NOT normally distributed, we should use other techniques, one of which is this IQR method
"""



"""# Capping using IQR method"""

df_cap = df.copy()

def iqr_capping(df, cols, factor):
    
    for col in cols:
        
        q1 = df[col].quantile(0.25)
        q3 = df[col].quantile(0.75)
        
        iqr = q3 - q1
        
        upper_whisker = q3 + (factor*iqr)
        lower_whisker = q1 - (factor*iqr)
        
        df[col] = np.where(df[col]>upper_whisker, upper_whisker,
                 np.where(df[col]<lower_whisker, lower_whisker, df[col]))

iqr_capping(df_cap, features, 1.5)

for col in features:
    plt.figure(figsize=(16,4))
    
    plt.subplot(141)
    sns.distplot(df[col], label="skew: " + str(np.round(df[col].skew(),2)))
    plt.title('Before')
    plt.legend()
    
    plt.subplot(142)
    sns.distplot(df_cap[col], label="skew: " + str(np.round(df_cap[col].skew(),2)))
    plt.title('After')
    plt.legend()
    
    plt.subplot(143)
    sns.boxplot(df[col])
    plt.title('Before')
    
    plt.subplot(144)
    sns.boxplot(df_cap[col])
    plt.title('After')
    plt.tight_layout()
    plt.show()



"""# Trimming using IQR method"""

df_trim = df.copy()

def iqr_trimming(df, cols, factor):
    
    drop_outliers = np.array([])
    
    for col in cols:
        
        q1 = df[col].quantile(0.25)
        q3 = df[col].quantile(0.75)
        
        iqr = q3 - q1
        
        upper_whisker = q3 + (factor*iqr)
        lower_whisker = q1 - (factor*iqr)
        
        s = df[col]
        
        indexes = s[(s > upper_whisker) | (s< lower_whisker)].index
        
        drop_outliers = np.append(drop_outliers, indexes)
    
    return drop_outliers

s = df['Population']
s[(s > 3000) | (s<20)].index

dropped = np.unique(iqr_trimming(df_trim, features, 1.5))

df_trim.drop(dropped, inplace=True)

df_trim.shape

df.shape

20640-16842

3798/20640



for col in features:
    plt.figure(figsize=(16,4))
    
    plt.subplot(141)
    sns.distplot(df[col], label="skew: " + str(np.round(df[col].skew(),2)))
    plt.title('Before')
    plt.legend()
    
    plt.subplot(142)
    sns.distplot(df_trim[col], label="skew: " + str(np.round(df_trim[col].skew(),2)))
    plt.title('After')
    plt.legend()
    
    plt.subplot(143)
    sns.boxplot(df[col])
    plt.title('Before')
    
    plt.subplot(144)
    sns.boxplot(df_trim[col])
    plt.title('After')
    plt.tight_layout()
    plt.show()











for col in features:
    plt.figure(figsize=(16,4))
    
    plt.subplot(141)
    sns.distplot(df[col], label="skew: " + str(np.round(df[col].skew(),2)))
    plt.title('Before')
    plt.legend()
    
    plt.subplot(142)
    sns.distplot(df_cap[col], label="skew: " + str(np.round(df_cap[col].skew(),2)))
    plt.title('After')
    plt.legend()
    
    plt.subplot(143)
    sns.boxplot(df[col])
    plt.title('Before')
    
    plt.subplot(144)
    sns.boxplot(df_cap[col])
    plt.title('After')
    plt.tight_layout()
    plt.show()

"""#### We should ideally split the dataset into training and testing and then apply the outlier engineering techniques onto the training set, because we want to keep the test set untouched until the very end.

#### We'll want see how such a model performs on unseen data which may or may not contain outliers

#### But here, we'll assume that the entire data we have is our train set, and that we have a separate test set waiting for us

# Winsorizing Outliers
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
from scipy import stats
import seaborn as sns

from sklearn.datasets import fetch_california_housing
ca = fetch_california_housing()

dir(ca)

X = ca.data

y = ca.target

data = np.concatenate((X,y.reshape(-1,1)), axis=1)

df = pd.DataFrame(data, columns=ca.feature_names+['target'])
df.head()

df.drop(['Latitude', 'Longitude'], axis=1, inplace=True)

features = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup',]
features

sns.set_style('dark')
for col in features:
    plt.figure(figsize=(15,4))
    plt.subplot(131)
    sns.distplot(df[col], label="skew: " + str(np.round(df[col].skew(),2)))
    plt.legend()
    plt.subplot(132)
    sns.boxplot(df[col])
    plt.subplot(133)
    stats.probplot(df[col], plot=plt)
    plt.tight_layout()
    plt.show()



"""# Capping using Percentile method"""

df_cap = df.copy()

def percentile_capping(df, cols, from_low_end, from_high_end):
    
    for col in cols:
        
#         lower_bound = df[col].quantile(from_low_end)
#         upper_bound = df[col].quantile(1-from_high_end)
        
#         df[col] = np.where(df[col]>upper_bound, upper_bound,
#                  np.where(df[col]<lower_bound, lower_bound, df[col]))

        stats.mstats.winsorize(a=df[col], limits=(from_low_end, from_high_end), inplace=True)

# fourth argument of 0.01 from right end is equivalent to saying
# 1-0.01 = 0.99 quantile from the left end
percentile_capping(df_cap, features, 0.01, 0.01)

df_cap.describe()

df.describe()

df['Population'].quantile(0.99)







for col in features:
    plt.figure(figsize=(16,4))
    
    plt.subplot(141)
    sns.distplot(df[col], label="skew: " + str(np.round(df[col].skew(),2)))
    plt.title('Before')
    plt.legend()
    
    plt.subplot(142)
    sns.distplot(df_cap[col], label="skew: " + str(np.round(df_cap[col].skew(),2)))
    plt.title('After')
    plt.legend()
    
    plt.subplot(143)
    sns.boxplot(df[col])
    plt.title('Before')
    
    plt.subplot(144)
    sns.boxplot(df_cap[col])
    plt.title('After')
    plt.tight_layout()
    plt.show()

import pandas as pd
data = pd.read_csv('car_evaluation.csv')
data.head()

data.shape

data.outcome.value_counts()

X = data.iloc[:,:-1]
y = data.outcome
X.head()



from sklearn.preprocessing import LabelEncoder
enc = LabelEncoder()
X.loc[:,['buying','maint','lug_boot','safety']] = \
X.loc[:,['buying','maint','lug_boot','safety']].apply(enc.fit_transform)
X.head()

from sklearn.model_selection import train_test_split
X_train,X_test, y_train,y_test = \
train_test_split(X,y,test_size=0.3,random_state=10)

from sklearn.neighbors import KNeighborsClassifier
model = KNeighborsClassifier()
model.fit(X_train,y_train)
y_predict = model.predict(X_test)

from sklearn.metrics import accuracy_score
print(accuracy_score(y_test,y_predict))
pd.crosstab(y_test,y_predict)

17/25

"""# SMOTE-Handling Imbalanced dataset"""

pip install imblearn

from imblearn.over_sampling import SMOTE
smote = SMOTE()

X_train_smote, y_train_smote = smote.fit_sample(X_train.astype('float'),y_train)

from collections import Counter
print("Before SMOTE :" , Counter(y_train))
print("After SMOTE :" , Counter(y_train_smote))

model.fit(X_train_smote,y_train_smote)
y_predict = model.predict(X_test)
print(accuracy_score(y_test,y_predict))
pd.crosstab(y_test,y_predict)

23/25

"""# Upsampling for imbalanced data"""

# Target variable count
target_count = bank_data.Exited.value_counts()
print('Class 0:', target_count[0])
print('Class 1:', target_count[1])

#Lets see the proportion of the imbalance of the classes.
print('Proportion:', round(target_count[0] / target_count[1], 2), ': 1')
target_count.plot(kind='bar', title='Count (target)');

# Class count
count_class_0, count_class_1 = bank_data.Exited.value_counts()

# Divide by class
df_class_0 = bank_data[bank_data['Exited'] == 0]
df_class_1 = bank_data[bank_data['Exited'] == 1]

df_class_1_over = df_class_1.sample(count_class_0, replace=True)
bank_data_over = pd.concat([df_class_0, df_class_1_over], axis=0)

print('Random over-sampling:')
print(bank_data_over.Exited.value_counts())

bank_data_over.Exited.value_counts().plot(kind='bar', title='Count (target)')

"""# Fancy Imputer(MICE) and 8 other imputer algorithms

# Install fancyimpute package
"""

!pip install fancyimpute

from fancyimpute import KNN, NuclearNormMinimization, SoftImpute, BiScaler

# X is the complete data matrix
# X_incomplete has the same values as X except a subset have been replace with NaN

# Use 3 nearest rows which have a feature to fill in each row's missing features
X_filled_knn = KNN(k=3).fit_transform(X_incomplete)

# matrix completion using convex optimization to find low-rank solution
# that still matches observed values. Slow!
X_filled_nnm = NuclearNormMinimization().fit_transform(X_incomplete)

# Instead of solving the nuclear norm objective directly, instead
# induce sparsity using singular value thresholding
X_incomplete_normalized = BiScaler().fit_transform(X_incomplete)
X_filled_softimpute = SoftImpute().fit_transform(X_incomplete_normalized)

# print mean squared error for the  imputation methods above
nnm_mse = ((X_filled_nnm[missing_mask] - X[missing_mask]) ** 2).mean()
print("Nuclear norm minimization MSE: %f" % nnm_mse)

softImpute_mse = ((X_filled_softimpute[missing_mask] - X[missing_mask]) ** 2).mean()
print("SoftImpute MSE: %f" % softImpute_mse)

knn_mse = ((X_filled_knn[missing_mask] - X[missing_mask]) ** 2).mean()
print("knnImpute MSE: %f" % knn_mse)

"""# MICE imputation"""

from fancyimpute import IterativeImputer as MICE
MICE().fit_transform(df)

from fancyimpute import IterativeImputer
mice_impute = IterativeImputer()
traindatafill = Mice_impute.fit_transform(traindata)

'''!pip install statsmodels
statsmodels.imputation.mice.MICE
Also refer this  https://www.statsmodels.org/stable/generated/statsmodels.imputation.mice.MICE.html
'''

from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer

import numpy as np
from sklearn.linear_model import LinearRegression
lr = LinearRegression()#  can keep anything as estimator
imp = IterativeImputer(estimator = lr, verbose = 0, missing_values = np.nan, tol = 1e-10, imputation_order = 'roman')

"""# Iterative imputer."""

import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

import sklearn
sklearn.__version__

from sklearn.experimental import enable_iterative_imputer

from sklearn.impute import IterativeImputer

df = pd.DataFrame({
    'age': [25,27,29,31,33,np.nan],
    'experience': [np.nan, 3,5,7,9,11],
    'salary': [50, np.nan, 110,140,170,200],
    'purchased' : [0,1,1,0,1,0]
})
df

X = df.drop('purchased', 1)
y = df['purchased']

X

X.corr()

lr = LinearRegression()
# I'm using Linear Regression because all the features are highly correlated with each other
# In most real life datasets, they will be not, and the need will arise to use other regressors

imp = IterativeImputer(estimator=lr, verbose=2, max_iter=30, tol=1e-10, imputation_order='roman')
# play around with the max_iter and tol parameters to get a better feel of how it is working

# to find "scaled tolerance", multiply the tolerance with the max of the absolute values
# in the original dataset 
1e-10 * 200

imp.fit_transform(X)

"""##### how the n_nearest_features parameter works:
(refer the video for better understanding)
https://youtu.be/1n7ld38PjEc
"""

# imagine we have a dataset with 6 features, one of which is age.
# Now we want to predict the NaNs in age
# so we find the absolute correlation coefficient between age and all other features
corr_values = [0.9, 0.5, 0.8, 0.4, 0.1]
corr_values

np.sum(corr_values)

0.9/2.7

from sklearn.preprocessing import normalize

# we'll normalize the absolute correlation coefficients to have a sum of one
probs = normalize([corr_values], norm='l1')
probs = probs.ravel()
probs

probs.sum()

# now we'll pick the number of neighbors we want (2 in this case) and set
# the weight/probabilites parameter as the 'probs' we calculated above
# so that numpy assigns the proportional weight to each feature according
# to the correlation of that feature with the target feature (age in this case)

np.random.choice([1,2,3,4,5], 2, replace=False, p=probs)



"""##### to demonstrate working of Iterative Imputer in the case of training and testing sets"""

df = pd.DataFrame({
    'age': [25,27,29,31,33,np.nan,37,39,41,np.nan,45],
    'experience': [np.nan, 3,5,7,9,11,13,16,np.nan,19,21],
    'salary': [50, np.nan, 110,140,170,200,230,260,np.nan,320,350],
    'purchased' : [0,1,1,0,1,0,0,1,1,0,0]
})
df

X = df.drop('purchased', 1)
y = df['purchased']

X

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

X_train

lr = LinearRegression()
imp = IterativeImputer(estimator=lr, tol=1e-10, max_iter=1, verbose=2, imputation_order='roman')
imp.fit_transform(X_train)

X_train.mean()

# For the inital imputation of test set, the missing values in test set will be filled 
# with the means of the respective columns in the train set
X_test



# this is the sequence of steps that will be followed for doing the imputations.
# remember, we are using the "roman" imputation order, hence the order of
# imputations is 0, 1, 2 etc in that order.
imp.imputation_sequence_

# to estimate the age missing value in first iteration (test set)
print(imp.imputation_sequence_[0][2].coef_)
print(imp.imputation_sequence_[0][2].intercept_)

19*0.46068289 + 320*0.04777397 + 19.798858287238644

imp.transform(X_test)



# to estimate the experience missing value in first iteration (test set)
print(imp.imputation_sequence_[1][2].coef_)
print(imp.imputation_sequence_[1][2].intercept_)

1.02317467*41 + 0.00381208 *165.71 - 25.23203142007218

# to estimate the salary missing value in first iteration (test set)
print(imp.imputation_sequence_[2][2].coef_)
print(imp.imputation_sequence_[2][2].intercept_)

9.91419532 *41 + 4.81517967*17.349 - 200.1326100334477